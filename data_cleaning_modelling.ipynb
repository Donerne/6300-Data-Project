{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AAPL_stock_news_sentiment</th>\n",
       "      <th>AAPL_press_release_sentiment</th>\n",
       "      <th>AAPL_twitter_social_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2021</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2022</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2023</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2024</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>31-12-2021</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>31-12-2022</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>31-12-2023</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>31-12-2024</td>\n",
       "      <td>weakly_positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strongly_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2433 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date AAPL_stock_news_sentiment AAPL_press_release_sentiment  \\\n",
       "0     01-01-2020           weakly_positive                          NaN   \n",
       "1     01-01-2021           weakly_positive                          NaN   \n",
       "2     01-01-2022           weakly_positive                          NaN   \n",
       "3     01-01-2023           weakly_positive                          NaN   \n",
       "4     01-01-2024           weakly_positive                          NaN   \n",
       "...          ...                       ...                          ...   \n",
       "2428  31-12-2020           weakly_positive                          NaN   \n",
       "2429  31-12-2021                   neutral                          NaN   \n",
       "2430  31-12-2022           weakly_positive                          NaN   \n",
       "2431  31-12-2023           weakly_positive                          NaN   \n",
       "2432  31-12-2024           weakly_positive                          NaN   \n",
       "\n",
       "     AAPL_twitter_social_sentiment  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "...                            ...  \n",
       "2428                           NaN  \n",
       "2429                           NaN  \n",
       "2430                           NaN  \n",
       "2431                           NaN  \n",
       "2432             strongly_positive  \n",
       "\n",
       "[2433 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in datasets common to all companies\n",
    "historical_sector_performance = pd.read_csv(\"market_performance/historical_sector_performance.csv\")\n",
    "sector_pe_ratio = pd.read_csv(\"market_performance/sector_pe_ratio.csv\")\n",
    "inflation_rates_data = pd.read_csv(\"inflation_rates_data.csv\")\n",
    "treasury_rates_data = pd.read_csv(\"treasury_rates_data.csv\")\n",
    "\n",
    "# Setting company names \n",
    "commodity_names = ['Palladium', 'Copper', 'Lithium', 'Silver', 'Gold']\n",
    "# Setting forex names \n",
    "forex_names = ['CADUSD', 'CHFUSD', 'CNHUSD', 'KRWUSD', 'EURUSD', 'GBPUSD', 'JPYUSD']\n",
    "\n",
    "# Dictionaries to store datasets\n",
    "commodity_data = {}\n",
    "forex_data = {}\n",
    "\n",
    "# reading in files\n",
    "for names in commodity_names:\n",
    "\n",
    "    try:\n",
    "        commodity_data[f\"{names}_commodity_data\"] = pd.read_csv(f\"commodity_data/{names}_commodity_data.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {names}: {e}\")\n",
    "        continue\n",
    "\n",
    "# reading in files\n",
    "for names in forex_names:\n",
    "\n",
    "    try:\n",
    "        forex_data[f\"{names}_forex_data\"] = pd.read_csv(f\"forex_data/{names}_forex_data.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {names}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "# Loading required datasets unique to each company\n",
    "company_list = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "\n",
    "company_stock_prices = {}\n",
    "company_technical_indicators = {}\n",
    "company_complete_news_data = {}\n",
    "for company in company_list:\n",
    "    try:\n",
    "        company_stock_prices[f\"{company}_stock_prices\"] = pd.read_csv(f\"Stock_Price_Data/{company}_stock_prices.csv\")\n",
    "        company_technical_indicators[f\"{company}_technical_indicators\"] = pd.read_csv(f\"technical_indicators/Merged_Technical_Indicators/{company}_Technical_Indicators.csv\")\n",
    "        company_technical_indicators[f\"{company}_technical_indicators\"].rename(columns={'volume' : 'tech_ind_traded_volume'}, inplace=True)\n",
    "        company_complete_news_data[f\"{company}_complete_news_data\"] = pd.read_csv(f\"complete_news_data/{company}_complete_news_data.csv\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {company}: {e}\")\n",
    "        continue\n",
    "\n",
    "company_complete_news_data['AAPL_complete_news_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in training data:\n",
      "False    5131\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicates = historical_sector_performance.duplicated()\n",
    "\n",
    "print(\"Duplicate rows in training data:\")\n",
    "print(duplicates.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates on historical sector data removed. Number of rows remaining: 5131\n"
     ]
    }
   ],
   "source": [
    "historical_sector_performance.drop_duplicates(inplace=True)\n",
    "\n",
    "print('Duplicates on historical sector data removed. Number of rows remaining:', historical_sector_performance.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished collecting and organising data for AAPL.\n",
      "Finished collecting and organising data for AMZN.\n",
      "Finished collecting and organising data for GOOG.\n",
      "Finished collecting and organising data for MSFT.\n",
      "Finished collecting and organising data for META.\n",
      "Finished collecting and organising data for NVDA.\n"
     ]
    }
   ],
   "source": [
    "# Creating loop to join all datasets for each company\n",
    "company_symbol_list = [\"AAPL\", \"AMZN\", \"GOOG\", \"MSFT\", \"META\", \"NVDA\"]\n",
    "\n",
    "datasets_lists = {}\n",
    "full_datasets = {}\n",
    "\n",
    "# creating lists with datasets for each company and looping through each company\n",
    "for company_symbol in company_symbol_list:\n",
    "    datasets_lists[f\"{company_symbol}_full_dataset\"] = [company_stock_prices[f'{company_symbol}_stock_prices'],\n",
    "                                                       sector_pe_ratio,\n",
    "                                                       historical_sector_performance,\n",
    "                                                       treasury_rates_data, \n",
    "                                                       inflation_rates_data, \n",
    "                                                       *[commodity_data[company] for company in commodity_data],\n",
    "                                                       *[forex_data[forex] for forex in forex_data],\n",
    "                                                       company_technical_indicators[f'{company_symbol}_technical_indicators'],\n",
    "                                                       company_complete_news_data[f'{company_symbol}_complete_news_data']]\n",
    "    \n",
    "\n",
    "    # joining up multiple datasets simultaneously\n",
    "    full_datasets[f\"{company_symbol}_raw_complete_data\"] = reduce(lambda left, right: pd.merge(left, right, on='date', how='left'), datasets_lists[f\"{company_symbol}_full_dataset\"])\n",
    "\n",
    "\n",
    "# Creating Nvidia data to add\n",
    "nvidia_data_to_add = company_stock_prices['NVDA_stock_prices'].merge(company_complete_news_data['NVDA_complete_news_data'], on='date', how='left')\n",
    "\n",
    "\n",
    "# Adding Nvidia stock price features and Nvidia news sentiment features to all datasets (excluding Nvidia)\n",
    "for company_symbol in company_symbol_list:\n",
    "    \n",
    "    if company_symbol == \"NVDA\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        full_datasets[f\"{company_symbol}_raw_complete_data\"] = full_datasets[f\"{company_symbol}_raw_complete_data\"].merge(nvidia_data_to_add, on='date', how='left')\n",
    "    \n",
    "    # Writing all company datasets to csv after organising data\n",
    "    full_datasets[f\"{company_symbol}_raw_complete_data\"].to_csv(f\"full_complete_datasets/{company_symbol}_raw_complete_data.csv\", index=False)\n",
    "    print(f\"Finished collecting and organising data for {company_symbol}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
